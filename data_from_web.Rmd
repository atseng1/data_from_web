---
title: "Data From Web"
author: "Ashley Tseng"
date: "10/10/2019"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(rvest)
library(httr)
```



## Extracting tables
```{r}
url = "http://samhda.s3-us-gov-west-1.amazonaws.com/s3fs-public/field-uploads/2k15StateFiles/NSDUHsaeShortTermCHG2015.htm"
drug_use_xml = read_html(url)

drug_use_xml %>% 
  html_nodes(css = "table")
```

A useful way to extract things from a list is using double brackets:
```{r}
table_marj = 
  (drug_use_xml %>% html_nodes(css = "table")) %>% 
  .[[1]] %>%
  html_table() 
```



## CSS Selector

```{r HarryPotter}
hpsaga_html = 
  read_html("https://www.imdb.com/list/ls000630791/")

hp_movie_names = 
  hpsaga_html %>% 
  html_nodes(".lister-item-header a") %>% 
  html_text()

hp_movie_runtime = 
  hpsaga_html %>% 
  html_nodes(".runtime") %>% 
  html_text()

hp_movie_money = 
  hpsaga_html %>% 
  html_nodes(".text-small:nth-child(7) span:nth-child(5)") %>% 
  html_text()

hp_df =
  tibble(
    title = hp_movie_names,
    runtime = hp_movie_runtime,
    money = hp_movie_money
  )

```

```{r NapoleanDynamite}
url = "https://www.amazon.com/product-reviews/B00005JNBQ/ref=cm_cr_arp_d_viewopt_rvwer?ie=UTF8&reviewerType=avp_only_reviews&sortBy=recent&pageNumber=1"

dynamite_html = read_html(url)

review_titles = 
  dynamite_html %>%
  html_nodes(".a-text-bold span") %>%
  html_text()

review_stars = 
  dynamite_html %>%
  html_nodes("#cm_cr-review_list .review-rating") %>%
  html_text()

review_text = 
  dynamite_html %>%
  html_nodes(".review-text-content span") %>%
  html_text()

reviews = tibble(
  title = review_titles,
  stars = review_stars,
  text = review_text
)
```
Note that the particular URL only pulls the reviews from page 1. You can go through and change the page # in the URL, but this could take forever. Prof will show us a way to automate this process later on in the course.

## Using an API
```{r NYCWater}
nyc_water = 
  GET("https://data.cityofnewyork.us/resource/waf7-5gvc.csv") %>% 
  content("parsed")

nyc_water = 
  GET("https://data.cityofnewyork.us/resource/waf7-5gvc.json") %>% 
  content("text") %>%
  jsonlite::fromJSON() %>%
  as_tibble()
```
"GET" tells R to go to the website and get everything on the website.
The JSON format is messier than the .csv format. In this case, it boils down to something having to do with the data rectangle. JSON is a more flexible way to export data, but it requires additional parsing to get where you want to be when you download JSON data.


```{r BRFSS}
brfss_smart2010 = 
  GET("https://data.cdc.gov/api/views/acme-vg9e/rows.csv?accessType=DOWNLOAD") %>% 
  content("parsed")
```


```{r Pokemon}
poke = 
  GET("http://pokeapi.co/api/v2/pokemon/1") %>%
  content()

poke$name

poke$height

poke$abilities
```

